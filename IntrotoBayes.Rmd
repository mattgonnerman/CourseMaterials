---
title: "A Broad Introduction to Bayesian Statistics"
author: "Matthew Gonnerman"
date: "1/16/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

_A Note to Readers: This module is a work in progress_

### Outline:
[Objectives]      
[Sources]

### Objectives

This module is intended as a starting point for learning about Bayesian statistics, specifically aimed at graduate students studying ecology who are unfamiliar or uncomfortable with statistics in general. It should not be considered a comprehensive summary but rather as a means of entry that hopefully will give you confidence to further explore these concepts further.  To that end, I wrote this module with the following objectives in mind...  
&ensp;&ensp;&ensp;1) To provide a broad, introductory description of Bayesian philosophy.  
&ensp;&ensp;&ensp;2) To breakdown the mechanisms by which Bayesian statistics functions as well as provide a brief summary of one of its most commonly used tools, Markov chain Monte Carlo simulations.  
&ensp;&ensp;&ensp;3) To differentiate a Bayesian approach from the more commonly taught Frequentist approach.  
&ensp;&ensp;&ensp;_4) To force myself to learn RMarkdown (This one is just for me)_ 

### Common Nomenclature and Symbols
Before we jump head first into statistical philosophy, let's first take a moment to make sure we all have a baseline understanding on how to read probabilities andgo over basic nomenclature and symbols you will encounter within this module. For those familiar with probabilities and statistics, this will be a review for you.  

[Models]
  
[COME BACK TO THIS AFTER EVERYTHING IS WRITTEN AND BREAKDOWN]

### How do you think about your data?:

If you are reading this module, I assume you are either being forced to at gunpoint or you are a graduate student with a need or desire to better understand your options when conducting analyses. While we may all have very different study systems and animals, we likely all have some things in common. First, we had to write a research proposal describing a statistical approach that we did not yet understand because our adviser suggested it to us. Second, we have a series of questions we hope to answer to aid in the management of our systems. And third, we possess (or will collect) a data set representing known information about our systems which we will use to address our research questions. For example, I studied population and movement ecology of game birds during graduate school. My research questions focused on the composition and distribution of wild turkey populations, such as how they use different land cover types during various seasons. To that end, I collected data on turkey locations using GPS and VHF radio-telemetry which, in combination with remotely sensed data products such as the National Land Cover Database, represented the data I had available to work with.

Regardless of the system we wish to study, information can be broken down into two categories: what is known and what is unknown. In the case of our turkey example, the knowns are the individual turkey location data and the associated land cover information. The unknowns are the underlying relationships that define how these two data sets relate to one another. Do turkeys select for a given land cover type consistently more than others? Is there some effect of weather on selection? Maybe turkey sex or age affects their decision-making process? What about time of day? For the sake of being on the same page, lets use this system and data as an example throughout the module. Specifically, we wish to know the magnitude of the effect of snow depth on turkey use of forested land cover. 

So now we have our data and the research questions we wish to answer, but we still need to determine how we will approach our analysis (ideally this is done in the planning stage of your research). Within the field of ecology, we tend to choose an approaches that fall within one of two paradigms, bayesian or frequentist statistics. While there are many similarities and distinctions between the two (which we will summarize at the end of this module), let's first discuss how each defines the relationship between known and unknown information. 

Both would look at our turkey resource selection question and say that there is some fixed parameter, $\theta$, that describes the effect size of snow depth on selection for forests. By fixed, we mean that there is some true value for $\theta$ that applies to our study system. We may not know it, but it exists (even if it is 0). We then treat our collected data, y, as random variables which are drawn from some larger pool of possible data. The data is random because if we were to go back out and collect new data, we would almost certainly get a different data set due to any number of factors such as measurement error, predator presence, or individual behavioral differences. We can describe the relationship between our known and unknown information using a probability statement, $Pr(y|\theta)$, which reads "the probability of collecting our observed data assuming some unknwon value for $\theta$."


These hypothetical resampling that the core of frequentists statistics lies. 

Despite this randomness, if there is some effect of snow depth on selection for forest, we would see some trend in our data that we can quantify.

The relationship between the data and $\theta$ can then be written as a probability statement, $Pr(y|\theta)$, which states "the probability of collecting data y given the unknwon value for $\theta$." This is also known as the *likelihood* and can be estimated using various methods (which is a topic for a different module). 

A Bayesian on th other hand treats \theta and y in the reverse, $Pr(\theta|y)$. 



































### Bayes Theorem:
[Why is it called bayesian statistics?]

$$ Pr(\theta|y) = \frac{Pr(y|\theta) Pr(\theta)}{Pr(y)}$$
[What are theta and y in this scenario] [Theta = unobserved] [y = observed]


### In plain english...
Without focusing on the individual components of the equation, it states...


### The Components
[Statistical Rethinking pf 36?]

Now that we understand what the equation says, lets examine the individual components and how they help reach that conclusion...



**Prior Distribution** - 

$$ \sum_j{Pr(y|\theta_j)} Pr(\theta_j) $$

### Why does this work?
Bayes theorem centers around the probability of theta and y both occuring at the same time, otherwise written as $Pr(y,\theta)$. [Green et al. has a good walkthrough on pg3]

[Avoid overloading with equations here, try to just talk it out and point to more specific examples]


### An Example:
To provide a more tangible example, lets apply Bayes theorem to a simple example. Assume...


### Bayesian vs Frequentist vs Maximum Likelihood

[Kery and Schaub - Bayesian pop analysis ch 2.4]

[Held and Bove - Likelihood and Bayesian Inference ch 3]

[Hobbs and Hooten - 4.2 Likelihood profiles] 

[Randomness (frequentist) vs uncertainty (Bayesian) - Nothing is actually random, if we had enough information and a powerful enough computer, you could predict almost any natural system in theory] 

### Sources and Further Reading

This module is a synthesis of the sources listed below.  
&ensp;&ensp;&ensp;???

For a more in depth discussion of the topics covered in this module, I have found the below resources very useful in furhtering my understanding of statistics.  
&ensp;&ensp;&ensp;