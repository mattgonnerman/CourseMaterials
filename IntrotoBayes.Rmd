---
title: "A Broad Introduction to Bayesian Statistics"
author: "Matthew Gonnerman"
date: "1/16/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

_A Note to Readers: This module is a work in progress_

### Outline:
[Objectives]      
[Sources]

### Objectives

This module is intended as a starting point for learning about Bayesian statistics, specifically aimed at graduate students studying ecology who are unfamiliar or uncomfortable with statistics in general. It should not be considered a comprehensive summary but rather as a means of entry that hopefully will give you confidence to further explore these concepts further.  To that end, I wrote this module with the following objectives in mind...  
&ensp;&ensp;&ensp;1) To provide a broad, introductory description of Bayesian philosophy.  
&ensp;&ensp;&ensp;2) To breakdown the mechanisms by which Bayesian statistics functions as well as provide a brief summary of one of its most commonly used tools, Markov chain Monte Carlo simulations.  
&ensp;&ensp;&ensp;3) To differentiate a Bayesian approach from the more commonly taught Frequentist approach.  
&ensp;&ensp;&ensp;_4) To force myself to learn RMarkdown (This one is just for me)_ 

### Common Nomenclature and Symbols
Before we jump head first into statistical philosophy, let's first take a moment to make sure we all have a baseline understanding on how to read probabilities andgo over basic nomenclature and symbols you will encounter within this module. For those familiar with probabilities and statistics, this will be a review for you.  
  
[COME BACK TO THIS AFTER EVERYTHING IS WRITTEN AND BREAKDOWN]

### Let's get started:

If you have made it this far, I assume you are either being forced to at gunpoint or you are a graduate student with a need or desire to better understand your options when conducting analysis for your research. While we may all have very different study systems and animals, we likely all have some things in common. First, we had to write a research proposal describing a statistical approach that we did not yet understand because our adviser suggested it to us. Second, we have a series of questions we hope to answer to aid in the management of our systems. And third, we possess (or will collect) a data set representing known information about our systems which will allow us to answer our research questions. 

For example, I studied population and movement ecology of game birds during graduate school. My research questions focused on the composition and distribution of wild turkey populations, such as how they use different land cover types during various seasons. To that end, I collected data on turkey locations using GPS and VHF radio-telemetry which, in combination with remotely sensed data products such as the National Land Cover Database, represented the data I had available to answer my research questions.

[Need some segue here]. For any system that we wish to study, information can be broken down into two categories: what is known and what is unknown. In the case of our turkey example, the knowns are the individual turkey location data and the associated land cover information. The unknowns are the underlying relationships that define how these two data sets relate to one another. Do turkeys select for a given land cover type consistently more than others? Is there some effect of weather on selection? Maybe turkey sex or age affects their decision-making process? What about time of day? For the sake of all of us being on the same page, lets use this system and data as an example throughout this module. Specifically, you wish to know the magnitude of the effect of snow depth on turkey use of forested land cover. 

So now we have our data and the research questions we wish to answer, but we still need to determine how we will approach our analysis. Within the field of ecology, we tend to choose an approach that can fall within one of two paradigms, Bayesian or Frequentist statistics. While there are many similarities and distinctions between the two (which we will summarize at the end of this module), one fundamental difference focuses on how we treat the relationship between our known and unknown information. 

A Frequentist would look at our turkey resource selection question and say that there is some fixed parameter, \theta, that describes the effect size of snow depth on turkey selection. By fixed, we mean that there is some true value for this effect size that applies to our study system. We then treat our collected data, y, as random variables which are drawn from some larger pool of possible values. In this way, we can account for randomness in data collection associated with things such as errors in data collection or influences of unmeasured effects. Probabilsitically, this would be written as $Pr(y|\theta)$ and read as "the probability of collecting data y given some known value for \theta." [On the right track but need to go and double check my definition of frequentist]

A Bayesian on th other hand treats \theta and y in the reverse, $Pr(\theta|y)$. 



































### Bayes Theorem:
[Why is it called bayesian statistics?]

$$ Pr(\theta|y) = \frac{Pr(y|\theta) Pr(\theta)}{Pr(y)}$$
[What are theta and y in this scenario] [Theta = unobserved] [y = observed]


### In plain english...
Without focusing on the individual components of the equation, it states...


### The Components
[Statistical Rethinking pf 36?]

Now that we understand what the equation says, lets examine the individual components and how they help reach that conclusion...



**Prior Distribution** - 

$$ \sum_j{Pr(y|\theta_j)} Pr(\theta_j) $$

### Why does this work?
Bayes theorem centers around the probability of theta and y both occuring at the same time, otherwise written as $Pr(y,\theta)$. [Green et al. has a good walkthrough on pg3]

[Avoid overloading with equations here, try to just talk it out and point to more specific examples]


### An Example:
To provide a more tangible example, lets apply Bayes theorem to a simple example. Assume...


### Bayesian vs Frequentist vs Maximum Likelihood

[Kery and Schaub - Bayesian pop analysis ch 2.4]

[Held and Bove - Likelihood and Bayesian Inference ch 3]

[Hobbs and Hooten - 4.2 Likelihood profiles] 


### Sources and Further Reading

This module is a synthesis of the sources listed below.  
&ensp;&ensp;&ensp;???

For a more in depth discussion of the topics covered in this module, I have found the below resources very useful in furhtering my understanding of statistics.  
&ensp;&ensp;&ensp;