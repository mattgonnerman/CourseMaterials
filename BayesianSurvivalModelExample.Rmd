---
title: "A Practical Introduction to Bayesian Modeling"
subtitle: "Wild Turkey Survival in JAGS/NIMBLE"
author: "Matthew Gonnerman"
output: html_document
---

```{r, setup, include=FALSE}
lapply(c("dplyr",
         # "ggplot2", 
         "R2jags",
         "RMark", 
         "gtools"),
       require,
       character.only = T,
       quietly = T) #Whether to report successful loading of packages 
```
### Outline:
[Objectives]  
[Setting Up the R Environment]  
[Describing Our Model System]  
[Simulating our Model System]  
[From Hypothesis to Model]  
[MCMC: Sampling from the Posterior]   
[Translating Model to Code: An Example in JAGS]  
[A Bayesian Alternative: NIMBLE]
[A Frequentist Alternative: RMark]  
[Comparing Bayesian and Frequentist Approaches]  
[Sources and Other Resources]  

### Objectives
  
In graduate school, I set out to teach myself Bayesian statistics but I quickly found the entire introductory process to be extremely daunting, especially as an wildlife ecology student reading mostly statistics textbooks. There are a definitely a plethora of helpful books tailored to ecological questions which go into great detail on the theory and application of Bayesian statistics, but they often require a level of statistical knowledge that is difficult to obtain by simply reading along and rerunning the code. What ultimately worked for me was a much more applied approach. I just started coding using what I knew, solved individual problems as they arose, and luckily the understanding of the stats came after I was more familiar with the tools and process. So with that in mind, I have laid out this module to try emulate my learning experience, focusing on the coding and implementation of a simple model, and only bringing up relevant statistics as they appear. In this way, we can more adequately highlight the decisions and issues, without getting overwhelmed with equations and theory. 

My hope is that via my intermediate comfort level with the Bayesian process, I can more effectively translate expert knowledge for beginners just starting out. With that being said, this module is intended as a starting point for learning about the application of Bayesian statistics, specifically aimed at graduate students studying ecology who are unfamiliar or uncomfortable with statistics in general. It should not be considered a comprehensive description but rather a means of entry that hopefully will give you confidence to further explore these concepts. I have stripped away much of the details to distill what is most relevant for ecologists trying to build and evaluate statistical models. My goal is not necessarily to make you a perfect Bayesian statisticians, but rather provide you with a manual for how to run analysis with the Bayesian tool set. To that end, I wrote this module with the following objectives in mind...   
  
<div style="margin-left: 1em;"> 1) To demonstrate how to run a bayesian survival analysis in R from conception through model diagnostics.   
2) To outline common decisions that must be made throughout process and provide relevant background to inform that decision making process. 
3) Compare methods and results from a bayesian and frequentist approach to help show when each framework is most appropriate to use.  
4) _To force myself to better understand these concepts and to learn RMarkdown in the process (This one is just for me, but at least now you know why someone would do this in the first place)._ </div>


### Setting Up the R Environment
While you can choose to write in any coding language, I will be using [the R coding environemnt](https://www.r-project.org/) which many of you will already be familiar with. R implemented within R-Studio is a very prevalent tool used by ecologists, partially because it is free and open source. If you are unfamiliar with R, then you will want to spend some time familiarizing yourself with [the R coding basics](https://support.rstudio.com/hc/en-us/articles/201141096-Getting-Started-with-R) before starting on this module.  
  
For those ready to jump in, we will first install, update, and load the necessary packages which we will use throughout our code. Just as a reminder, **if you are already working on other R coding projects, updating packages can have cascading effects on code functionality.** I only add this reminder as many people will go to install/update packages, causing their functioning code to suddenly stop working, and freak out. It doesn't mean you screwed up your code necessarily, you will just have to update it to match the new functionality. 

```{r, eval = F}
install.packages("dplyr", "gtools", "R2jags", "RMark")
lapply(c("dplyr", #Data management
         "gtools", #Easy link functions
         "R2jags", "RMark"), #Running models
       require, #Function called to load packages
       character.only = T) #Necessary for lapply functionality
```

In addition to making sure packages are loaded, we will also want to ensure that the programs we are using are correctly installed and communicating with R. We will be using 2 programs for this lesson; [JAGS](https://mcmc-jags.sourceforge.io/) and [MARK](http://www.phidot.org/software/mark/). I will talk about what these programs will be specifically used for later, so let's just focus on getting them to work. Following the links provided, navigate to the installation pages and follow the instructions provided. Often times, if there are issues with this step, it is because the program was installed in an non-standard location (E.G. "C:\\Program Files").

This is also a good place to share some unsolicited advice which I received too late in my graduate career. Before you actually start coding, stop to think through the organization and workflow of your plan. Then, identify the major steps to implementing your code and consider breaking up your R script into sections that reflect these steps. Even with extensive comments, having 100's of lines of code within a single script can make reading code and diagnosing issues very difficult. By breaking up and sourcing our scripts like this, we can better create manageable chunks of code that are well organized and easily referenced. For example, here is how I usually break up and source my code, although I often times have even more divisions within each section depending on what type of modeling I am doing.   
```{r eval = F}
source("1 - DataManagementCode.R")
source("2 - JAGSModelCode.R")
source("3 - RunJAGSCode.R")
source("4 - SummarizeOutput.R")
source("5 - CreateFigures.R")
```


### Describing Our Model System
#### Research Question and Hypotheses
For this module, we will be asking questions about survival of individuals tracked using repeated observations of an individual. As this lesson is geared towards the Bayesian implementation of already conceived modeling techniques, I won't be going into much detail on the reasoning and derivation of survival models. For those unfamiliar, I would suggest <a href="https://doi.org/10.1890/0012-9658(2002)083[3476:ATFMAN]2.0.CO;2">Dinsmore et al. 2002</a> or, for a more detailed discussion on the data requirements and formatting, read [the MARK program documentation](http://www.phidot.org/software/mark/docs/book/pdf/chap17.pdf)

Since we all have different backgrounds and study animals, let's posit a hypothetical ecological question that is broadly relevant for management. I spent my graduate career studying wild turkey ecology, so let's use survival rates within turkey populations in New England as our study system. While in core areas of the species range, turkeys can subsist on hardwood mast throughout the winter, at their northern range limit, deep snow depths and icy conditions inhibit a turkey's ability to find adequate food sources. At the same time, low temperatures and high winds make thermoregulation more difficult, increasing energetic demands. If a state agency identfied winter as a major period of depressed survival for turkeys, they may wish to differentiate between these two causes of mortality as they could lead to different mitigation tacts. If inability to find natural food sources is depressing turkey survival, providing supplemental food sources during the winter would be a viable option for improving survival. If cold temperatures and wind are the issue, then a better management option may be to ensure adequate cold-weather refugia in areas where it is not currently available. So, to make sure we explicitly state our research question, we want to ask "How does winter weather impact the survival of wild turkeys in the northeastern United States." We will also want to explicitly state our hypothesis which will aid in model construction.  

<div style="margin-left: 1em;"> 
1) Decreased survival rates will be associated with increased snow depths.
2) Decreased survival rates will be associated with decreased temperatures.
</div>

But maybe we think there are other factors driving winter survival related to individual turkey behaviors and physiology. For example, body condition at capture may be a general indicator for how "healthy" a bird is, which may translate into variable survival throughout the winter. We can use weight and body measurements at capture to provide some metric of body condition which we can incorporate into our model. Alternatively, maybe the type of habitat a turkey occupies will influence the availability of natural and anthropogenic food sources. While we could collect very detailed location data to address such a hypothesis, for the purposes of this lesson we will simplify our data to describe dominant land cover classes found in individual turkey home ranges. So our two additional hypothesis will be...

<div style="margin-left: 1em;"> 
3) Decreased survival rates will be associated with decreased body condition metrics.
4) Turkeys that primarily occupy forested landscape will experience decreased survival compared to those that occupy agricultural or suburban landscapes.
</div>

#### Known and Unknown Information
Clearly stated hypotheses are important for producing unbiased scientific studies, but they are also useful for model building. By thinking about these concepts early in the process of formulating our model, we are able to identify components that will comprise the puzzle pieces that we need to fit together; random parameters and fixed data. To differentiate between what is a parameter and what is data, we can consider what information is known versus what is unknown. More specifically, what is "fixed" versus what is "random". Any fixed value that will not change within the model can be considered known. Conversely, if a[Known information is ... . It isn't overly complicated to see how the data we collect can be considered known, but unknwon information is a more abstract classification that could include a variety of concepts]. [List of potential unknown information types].  [Why do we need to differentiate between known and unknown info?].  
  
So let's apply these ideas to our model system and hypotheses. To answer questions about wild turkey winter survival, we can rely on radio-telemetry methodology to monitor individuals turkeys through the winter. The data we collect will be our known information comprised of the live/dead status of each bird over time. It will also include any ancillary information we want to relate to survival, which in our case is weather measurements (snow accumulation and temperature), individual turkey biometrics (body condition), and landscape information (major land cover class).


### Simulating our Model System
Now that we have laid out our research question and hypotheses, let's simulate some data. Simulated data will be  useful for learning these concepts but it also provides a level of control that facilitates model construction. Specifically, by generating the data ourselves, we will know whether our model outputs are accurate to the real values, which we can specify to be any value we wish. It also allows us to include as much or as little noise related to <abbr title="NEED A DEFINITION HERE">observation error</abbr> or <abbr title="NEED A DEFINITION HERE">process error,</abbr> which will allow us to assess how the model reacts to random variation in the data we provide it. If we were to start with real data, we would have much less capacity to determine whether the values we were getting were accurate.


[Useful to have all the known parameter values in the same place at the beginning of the code. Makes it easier to change and rerun everything.]
```{r}
##Simulated turkey survival
w.days <- 30  #the length of winter
mean.DSR <- 0.999  #base daily survival rate

alpha.s <- logit(mean.DSR) #Use logit link to create an intercept

# For every 1 sd increase in snow depth compared to the mean, probability of surviving a given day decreases by ...
beta.snow <- -.002 

# For every 1 sd increase in temperature compared to the mean, probability of surviving a given day increases by ...
beta.temp <- -.25 

# For every 1 sd decrease in body condition compared to the mean, probability of surviving a given day decreases by ...
beta.body <- -.003 

# In comparison to suburban landscapes, the probability of surviving a given day changes by ??? for turkeys in a agricultural/forested landscape...
beta.ag <- .1
beta.for <- -.5

```

```{r, echo = F}
winterSR <- mean.DSR^w.days  #base probability of surviving winter
print(paste("Mean Cumulative Winter Survival", winterSR, sep = " = "))

print(paste("Logit-Linked Intercept Value", alpha.s, sep = " = "))
gtools::inv.logit(alpha.s) - gtools::inv.logit(alpha.s+beta.snow)

gtools::inv.logit(alpha.s) - gtools::inv.logit(alpha.s+beta.temp)

gtools::inv.logit(alpha.s) - gtools::inv.logit(alpha.s+beta.body)

gtools::inv.logit(alpha.s) - gtools::inv.logit(alpha.s+beta.for)
```






We are going to survival for hypothetical turkeys in Maine. This has the benefit of letting us know we got the answer correct. So we are going to simulate a number of 3 month survival histories for birds. We are interested in January through March, when winter is the most harsh

Now that our R environment is ready, lets first lets define the relationships. Lets assume temperature and wind are driving short term changes in daily survival rate for this hypthetical population.

Define the relevant variables which will determine the dynamics of our system

[z-standardize, aids in interpretation and simplifies process. Encourage standardizing, can link to or show expample how to do.]




#### Simulate individual turkey characteristics and associated weather information
```{r}
n.turkey <- 200  #number of simulated turkeys

#Simulate individual turkey characteristics
turkey.sim <- matrix(NA, nrow = n.turkey, ncol = 3)
for(i in 1:n.turkey){
  turkey.sim[i,1] <- rnorm(1, mean = 0, sd = 1.5) #Body Condition Metric, referenced to mean body condition (pre-z-standardized)
  #Categorical covariate for Landscape, need dummy code it
  h <- sample(1:3, 1) #1 = Suburban, 2 = Agriculture, 3 = Forested
  turkey.sim[i,2] <-  ifelse(h == 2, 1, 0)
  turkey.sim[i,3] <-  ifelse(h == 3, 1, 0)
}

#Simulate daily weather characteristics
weather.sim <- matrix(NA, nrow = 2, ncol = w.days) #Create an empty matrix to place daily weather information into.
#For loop to populate the matrix
for(j in 1:w.days){
  #Snow Accumulation
  weather.sim[1,j] <- rlnorm(1, meanlog = log(1), sdlog = log(2)) #continuous lognormal distribution
  #Temperature
  weather.sim[2,j] <- rnorm(1, mean = 20, sd = 10) #sample discrete unifrom. option to provide a vector of probabilities to weight samples.
}

#Since we created our weather data to match how it is normally measured, lets next z-standardize the simulated values so they make sense with our beta coefficients.
for(k in 1:2){
  weather.sim[k,] <- scale(weather.sim[k,], center = T, scale = T)
}

# Each turkey will also have unique pressures and differences in behavior which we did not measure but will still cause changes in survival rates, so we need to simulate these influences for each bird at each time step.
random.sim <- matrix(NA, nrow = n.turkey, ncol = w.days)
for(i in 1:n.turkey){
  for(j in 1:w.days){
    random.sim[i,j] <- rnorm(1, mean = 0, sd = 1)
  }
}

#We can now simulate each turkeys individual survival outcomes
#First lets find combine the weather information with the betas we defines to create and unlinked probability
ind.daily.prob <- matrix(NA, nrow = n.turkey, ncol = w.days)
for(i in 1:n.turkey){
  for(t in 1:w.days){
    ind.daily.prob[i,t] <- alpha.s + beta.snow*weather.sim[1,t] + beta.temp*weather.sim[2,t] + beta.body*turkey.sim[i,1] + beta.ag*turkey.sim[i,2] + beta.for*turkey.sim[i,3] + random.sim[i,t]
    
    #We can now use the logit link to tranform into probabilities of surviving a given day
    ind.daily.prob[i,t] <- gtools::inv.logit(ind.daily.prob[i,t])
  }
}

#We can use a bernoulli trial (weighted coin flip) to simulate survival, assuming a bird was alive, need to make sure that they all start alive at capture, all birds assumed caught Dec 31. 

ind.surv.hist <- matrix(NA, nrow = n.turkey, ncol = w.days + 1)
ind.surv.hist[,1] <- 1

#Combine if/else statement with forloop to simulate

for(i in 1:n.turkey){
  for(t in 2:(w.days+1)){
    if(ind.surv.hist[i, t-1] == 1){
      ind.surv.hist[i, t] <- rbinom(1,1, ind.daily.prob[i,(t-1)])
    }else{
      break #ends the loop for this bird if it has died
    }
  }
}

#Before we move on, lets change the NAs in the matrix to 0, as once a bird dies it is dead for good.
ind.surv.hist[is.na(ind.surv.hist)] <- 0

#Encounter history for first bird
ind.surv.hist[1,]

#Lets see how many survived
sum(ind.surv.hist[,w.days + 1], na.rm = T)
 
```

####Simulate Resulting Survival history
So, now we are going to simulate some data that is collected from our simulated population. This may sound a bit silly, but it allows us to [EXPLAIN WHY THIS IS USEFUL] but. So, what kind of data would we collect to monitor survival? We could use radiotelemetry to monitor the live/dead status of a bird. With weekly checks, we could monitor for when a given bird dies, tracking it survival history. 

```{r}
obs.rate <- .95 #We can't expect to observe each turkey every day, so this just randomizes whether we successfully collect data on a bird on a given day. Let's assume that on average we find a bird every 4 days.

obs.hist.mat <- matrix(NA, nrow = n.turkey, ncol = w.days + 1)
obs.hist.mat[,1] <- 1 #We know the bird was alive at capture
#Now we can simulate our technicians going out and doing the work to collect our data.
for(i in 1:n.turkey){
  for(t in 2:(w.days+1)){
    succ.obs <- rbinom(1,1, obs.rate)
    
    if(succ.obs == 1){
      obs.hist.mat[i, t] <- ind.surv.hist[i, t]
      
      if(ind.surv.hist[i, t] == 0){ #if the bird is dead we would stop checking on it
        break #so we exit loop for this bird when we identify a mortality
      }
    }
  }
}
```
### From Hypothesis to Model
So lets check in. We have explicitly stated our research question and hypotheses which we wish to test. We have also collected data in the form of daily survival checks and weather information which constitutes our know information. We have also broadly identified our unknown information which we wish to estimate. So the next step is to create our model, which is where we describe the relationship between our known and unknown data. 

From here we are going to take a slight detour to just provide some context for how exactly we find estimates from this model, If you do not care to read about statistical theory (and who could blame you), you can just skip to where we discuss how to write probability statements describing our model ([Writing Our Model Out]).  

#### Bayes Theorem
Very briefly, I want to touch on the statistical theory for why this works, which begins with looking at the **joint probability** of two occurrences happening. To understand this, we will need to use probability theory. We can approach our question by considering the joint probability of our data and $\theta$ occurring together, otherwise written as $P(y, \theta)$. This probability can be rederived using basic rules of conditional probability and written a number of different ways, as shown below...   

$$ P(y, \theta) = Pr(\theta|y)Pr(y) = Pr(y|\theta) Pr(\theta)$$  

When we breakdown these probability statements, we find that the probability of both y and $\theta$ occurring together is the same as the probability of y occurring at all multiplied by the probability of $\theta$ occurring given that y also occurs (this can also be written with y and $\theta$ reversed). Using basic algebra, we can rearrange our equation to create the below statement, also referred to as Bayes Theorem.  


$$ Pr(\theta|y) = \frac{Pr(y|\theta) Pr(\theta)}{Pr(y)}$$
[Broad description]

#### Linking Theory and Information

**Likelihood** - XXX [Confusing nomenclature]  

**Prior Distribution** - XXX  [Defining but not exlusive component of bayesian analysis] [Informative priors]. [What can be a prior?] [Real data] [Expectations] [Benefits]  

[Uninformative priors] In the same way that a prior can represent our knowledge of a parameter, it can also be used to represent that we don't have any prior knowledge of a system and adjust our estimates accordingly, [Benefits of this]  

**Marginal Distribution** - XXX  [Probability of the data] [Can be calculated but doesn't have to be] [Explain basics the segue to...]  

**Joint Distribution** - XXX [Product of the likelihood and the prior] [Proportional to the Posterior. Means that where the joint distribution is maximized, so too will the posterior be maximized. Allows us to ignore the marginal distribution]  

**Posterior Distribution** - [This is the most important quantity in Bayesian inference, goal of the analysis.] [Represents information about unknown parameters based on the data and priors provided.] 

[Every posterior distribution used to be a prior]

#### Writing Our Model Out
Walk through the assumptions of the model and show how to code it. 

ADD A NON TIME VARYING COVARIATE TO DEMONSTRATE HOW THEY ARE CODED DIFFERENTLY

we have an issue, survival is varying according to time-varying covariates, so the model need to reflect that. Coded differently than a non-time varying covariate.

[DISCUSS SUBSCRIPTS/INDEXING]

#### PRIORS
base.S ~ Beta(1,1) # mean survival in restricted to between 0 and 1
a.S ~ log(base.S/(1-base.S)) #use logit link function to transform base.S into an intercept term for the regression
b.snow ~ Normal(mean = 0, sd = 1000)#uninformative prior for beta coefficient of effect of snow
b.temp ~ Normal(mean = -1, sd = 10)#weak informative prior for beta coefficient of effect of temperature
b.bodycondition ~ Normal(mean = -1, sd = 2)#strong but off base informative prior for beta coefficient of effect of average wind speed
b.ag ~ Normal(mean = 0, sd = 1000)#uniformative prior for beta coefficient of effect of agricultural landscape
b.for ~ Normal(mean = 0, sd = 1000)#uniformative prior for beta coefficient of effect of forested landscape
#### LIKELIHOOD
y[i,t] ~ Bernoulli(period.S)
period.S <- S.t1*S.t2*...*S.t?
logit(S.t) <- a.S + b.snow*x.snow[t] + b.ice*x.ice[t] + b.temp*x.temp[t] + b.wind*x.wind[t] 

### MCMC: Sampling from the Posterior
[Bayesian Inference is just counting]

[Simulated draws from the posterior]

#### Markvoc Chain Monte Carlo Simulations

[Potential Sampling Approaches]

### Translating Model to Code: An Example in JAGS
#### MCMC Decisions
There are quite a few options that need to be made when you run a MCMC. These will largely influence model convergence/run time.  [Broadly describe some decions.] The big issue many people run into when making these decisions which can slow them down is they are trying to find some correct answer, when in many cases these decisions are subject to the circumstances of the model, data, and researcher. So lets walk through some of these major questions.  

**Starting Values** - [Where you tell the MCMC to begin sampling for a given parameter value can affect run time] [For a correctly specified model, this shouldn't affect results]  

[In certain instances, if you let the model choose its own starting values, it can results in impossible relationships, which will cause errors when you try to run the model. For example, if you accidentally supply a negative value to a distribution constrained above 0. By specifying a starting value, you allow the model to start in a realistic location]

[Also important to note, these programs hate NA values. So this may be another place where you need to supply starting information so there are no NA values]

**Burn-in Time** -  

**Sampling Method** -  

**Coding Language** - There are many ways that you can code and run an MCMC. We will focus on two coding frameworks that are currently most widely used among ecologists **JAGS** and **NIMBLE**. [BUGS language]. [Similarities]. [Differences]. [When to choose one of the other].  

[Parallel Processing]

#### A JAGS Example
Translate our model into JAGS code

[Write model first, then worry about getting the data formatted correctly - Obviously make sure you aren't writing a model that can't use the data you have]

[Time varying covariate will require some cleverness]

#### Dynamic Indexing
https://mmeredith.net/blog/2021/JAGS_to_NIMBLE.htm

```{r}
JAGS.turkey.S.model <- function(){
  ###Priors
  base.S ~ dbeta(1,1) 
  a.S <- logit(base.S) 
  b.snow ~ dnorm(0, 1/1000)
  b.temp ~ dnorm(-1, 1/10)
  b.bc ~ dnorm(-1, 1/2) 
  b.ag ~ dnorm(0, 1/1000)
  b.for ~ dnorm(0, 1/1000)


  ###LIKELIHOOD
  for(i in 1:n.ind){
    for(t in 1:n.days){
      logit(DSR[i,t]) <- a.S + b.snow*x.snow[t] + b.temp*x.temp[t] + b.bc*x.bc[i] + b.ag*x.ag[i] + b.for*x.for[i]
    }
  }

  for(j in 1:n.obs){
    obs.S[j] ~ dbern(period.S[j]) #Probability of survival since previous check
    period.S[j] <- prod(DSR[turkey.id[j], (day.found[j] - (1:days.since[j]))]) #Aggregrate survival across missed days
  }
}
```
[dnorm using precision instead of sd, common so important to note]

[Indexing to make these work is one of the more difficult things for me.]

[If something is in the equation (= or ~ or <-), then it either needs a prior (b.snow ~ dnorm(0, 1/1000)), be reference to supplied information (obs.S), or be described by estimated or supplied parameters (period.S[i,j] <- prod(DSR[i, missed.days[i,j]])) ]

Reformatting data to get what we want.

```{r}
#[Remove first column because don't care about time before]
obs.hist.mat.noDay1 <- obs.hist.mat[,-1]

#Doesn't like NAs, so we need to remove them from the observation history. An easy way to do this is to convert it to a vector
obs.hist.vec <- as.vector(t(obs.hist.mat.noDay1))
obs.hist <- obs.hist.vec[!is.na(obs.hist.vec)]


#Because of how we specified DSR within the model, we will need a way to reference between our observation and survival rate. We can create two vectors to reference which bird each observation references and which days to reference for a given time period

#First lets find the number of days between each observation
obs.days <- data.frame(which(!is.na(obs.hist.mat), arr.ind = T)) %>% #What day did an observation occur for each turkey
  rename(Turkey = row, ObsDay = col) %>% 
  arrange(Turkey, ObsDay) %>% #Sort by turkey and day
  mutate(DaysSince = ifelse(ObsDay == 1, NA, ObsDay - lag(ObsDay))) #Make sure observations on day 1 don't count from previous bird.

turkey.id.mat <- day.found.mat <- days.since.mat <- matrix(NA, nrow = n.turkey, ncol = w.days+1)

for(i in 1:nrow(obs.days)){
  days.since.mat[obs.days$Turkey[i],obs.days$ObsDay[i]] <- obs.days$DaysSince[i]
}
days.since.vec <- as.vector(t(days.since.mat))
days.since <- days.since.vec[!is.na(days.since.vec)]

#Finally we will need a vector to reference which day a observation occurred on and a separate vector describing which turkey
for(t in 2:(1+w.days)){
  day.found.mat[, t] <- t
}
day.found.mat <- day.found.mat[,-1]
day.found.vec <- as.vector(t(day.found.mat))
day.found <- day.found.vec[!is.na(obs.hist.vec)]

for(i in 1:n.turkey){
  turkey.id.mat[i,] <- i
}
turkey.id.mat <- turkey.id.mat[,-1]
turkey.id.vec <- as.vector(t(turkey.id.mat))
turkey.id <- turkey.id.vec[!is.na(obs.hist.vec)]

```



Packaging everything up. As you can see in our model, we are going to need to reformatting of our data to get it into format our model can udnerstand and use. For example, I made a huge mistake when I initially thought up this model and thought of a time varying covariate (weather). These are much harder to code compared to characteristics of an individual or system that dont change between observations. This is specifically difficult because 
```{r}
#Data to supply to the model
data.list <- list(
  #Observation Information
  obs.S = obs.hist, #Vector containing observed survival history
  days.since = days.since, #Vector describing number of days since previous observation
  day.found = day.found, #Vector describing which day an observation occurred
  turkey.id = turkey.id, #Vector describing which turkey an observation was for
  n.ind = nrow(turkey.sim), #Number of individual turkeys monitored
  n.days = ncol(weather.sim), #Number of days in history
  n.obs = length(obs.hist), #Number of total observations
  
  #Covariate Information
  x.snow = weather.sim[1,], #Vector describing snow depth on a given day
  x.temp = weather.sim[2,], #Vector describing temperature on a given day
  x.bc = turkey.sim[,1], #Vector describing body condition for a given turkey
  x.ag = turkey.sim[,2], #Vector describing whether a turkey primarily uses agriculture landscape
  x.for = turkey.sim[,3] #Vector describing whether a turkey primarily uses forested landscape
)

#Parameter Monitors
parameters.null <-c(
  #Regression Coefficients
  "a.S",
  "b.snow",
  "b.temp",
  "b.bc",
  "b.ag",
  "b.for"
)

#Initial Values
inits.null <- function(){
  list(
    base.S = .998 #Set initial value for base survival rate
  )
}
```

#### Considerations for Run Time
One of the biggest goals of MCMC analysis is to have the model converge as quickly as possible. This helps to save time... There will be many factors affecting run time and many decisions you can make to reduce it. 

**Number of parameters to estimate** - [More nodes means more combinations means more simulations?]  
  
**Data Size** - [Amount of data you have will ]  
  
**Iterations** - [Longer simulations = bigger sample size esentially] 
  
**Burn In Period** - [Model needs time to find a stable equilibrium]    

**Thinning** - [Initially used to help with autocorrelation, but arguments against thinning...wasted data]  

**Number of Chains** -   
  
**Parallel Processing** -  

**Initial Values** - [Starting Closer to posterior maximum can aid in convergence]

[These decisions will be consistent across coding options, although implimentation may differ.]


#### Running the Model  
```{r}
#Make final MCMC related decisions
ni <- 2000 #Number of simulations to run
nb <- 1000 #Length of burnin in period
nt <- 1 #How much thinning should there be
nc <- 3 #Number of chains to run simultaneously

#Run the model
Surv_JAGS_output <- jags(data = data.list,
                        parameters.to.save = parameters.null,
                        inits = inits.null,
                        model.file = JAGS.turkey.S.model,
                        n.iter = ni,
                        n.burnin = nb,
                        n.thin = nt,
                        n.chains = nc) 
```
#### Common Errors
[Heather Gaya GitHub](https://github.com/heathergaya/JAGS-NIMBLE-Tutorials/tree/master/JAGS_Errors)

#### Model Diagnostics and Reporting Results (JAGS)
[Different components of the output object]

[Trace Plots]
```{r}
traceplot(Surv_JAGS_output, #bugs output object
          mfrow = c(3,2), #Rows and Columns in figure
          ask = F, #Ask before plotting?
          varname = c("b.ag", "b.for", "b.bc", "b.snow", "b.temp")) #Which parameters to plot
```

```{r}
#Basic Parameter Estimates
print(Surv_JAGS_output)
```

If we want to run a more in-depth diagnostics of our model, it can be useful to extract the actual MCMC chains. This allows for the running of various diagnostic functions.
```{r}
#Convert BUGS output into MCMC for further information and plotting options
Surv_JAGS_MCMC <- as.mcmc(Surv_JAGS_output)
summary(Surv_JAGS_MCMC)

```

```{r}
require(coda)
gelman.plot(Surv_JAGS_MCMC)

heidel.diag(Surv_JAGS_MCMC)
```

#### Failure to Converge
[Before rewriting your model, it may be worth first adjusting MCMC options] [Interations/BurnIn time] [Starting Values]

https://cran.r-project.org/web/packages/EcoDiet/vignettes/convergence_problems.html

[Using the original MCMC run to continue simulations with the same model]
```{r, eval = F}
Surv_JAGS_update <- update(Surv_JAGS_output, n.iter = 1000) #Continues the same simulation, adding iterations 
Surv_JAGS_update <- autojags(Surv_JAGS_output) #Automatically updates model until convergence
```

#### Evaluating and Presenting Results
[Posterior Distribution]

### A Bayesian Alternative: NIMBLE
[Same thing, but in nimble. Will skim over the theoretical and practical implications of our decisions and just show how to code them. ]
[Why use NIMBLE over JAGS]




[Very quickly show how easily this could be coded using RMark or whatever].  
  
So you may be thinking, "if its so easy to do this using a frequentist framework, why in the world did you make me do this long exercise?!."  

#### Direct Comparisons
**Integrating Models** - XXX  

**Intuitive Description of Uncertainty** - [Hypothetical Replicates vs Probability Statements]  

**Pior information** - XXX  

**Ease of Use** - XXX  

**Computational Limitations** - XXX  


[So now that you know how to do this under a bayesian framework, and you've seen how complicated it is, how would we run the same analysis as a frequentist?]

### A Frequentist Alternative: RMark 
[Phidot link](http://www.phidot.org/software/mark/docs/book/pdf/chap17.pdf)

#### Format the Data
```{r, warning=F, message=F}
EH.rmark <- as.data.frame(obs.hist.mat)[-1,] %>%
  mutate(TurkID = row_number()) %>%
  rowwise() %>%
  mutate(FirstFound = 1, #Conveniently, all of our simulated birds were caught on the same day
         LastPresent = max(which(c_across(1:(w.days)) == 1)), #When was the turkey last observed alive
         LastChecked = max(which(!is.na(c_across(1:(w.days))))), #When was the turkey first observed dead
         Fate = min(c_across(everything()), na.rm = T), #What was the final known fate of a bird through the period of itnerest?
         Freq = 1) %>% #Number of repetitions of a given encounter history, I don't usually aggregate
  mutate(LastChecked = ifelse(Fate == 1, w.days + 1, LastChecked)) %>%
  # mutate(LastChecked = ifelse(FirstDead > LastAlive)) %>%
  dplyr::select(TurkID,
                FirstFound, 
                LastPresent,
                LastChecked,
                Fate,
                Freq)

indcov.rmark <- as.data.frame(turkey.sim) %>%
  rename(BC = V1, Ag = V2, For = V3) %>%
  mutate(TurkID = row_number(), 
         Ag = as.factor(Ag), #RMark will convert automatically, but can preemptively do this to avoid messages
         For = as.factor(For))

data.rmark <- merge(EH.rmark, indcov.rmark)

WintSurv.process = process.data(data.rmark,
                               model="Nest", #We will run this in a nest survival framework
                               nocc=w.days + 1, #Number of occassions in the EH
                               groups=c("Ag", "For")) #Identify categorical covariates here
WintSurv.ddl = make.design.data(WintSurv.process)


## Add Daily Weather data to design data
weather.cov<- data.frame(seq(1,w.days,1))
colnames(weather.cov)<- c("time")
weather.cov$Snow<- weather.sim[1,]
weather.cov$Temp<- weather.sim[2,]

WintSurv.ddl$S=merge_design.covariates(WintSurv.ddl$S,weather.cov,bygroup=FALSE, bytime=TRUE)

```


####Run the model and compare
```{r, error = F, message = F, warning=F}
require(RMark)
RMark.model <- mark(WintSurv.process, 
                    WintSurv.ddl, 
                    model.parameters=list(S=list(formula =~ BC + Ag + For + Snow + Temp, 
                                                 link="logit")))

summary(RMark.model)

```

### Comparing Bayesian and Frequentist Approaches
**Definition of Unknown Parameters** - XXX  

**Randomness vs Uncertainty** - [Randomness (frequentist) vs uncertainty (Bayesian) - Nothing is actually random, if we had enough information and a powerful enough computer, you could predict almost any natural system in theory]  

**Pior information** - XXX  

**Ease of Use** - XXX  

**Computational Limitations** - XXX  


[Kery and Schaub - Bayesian pop analysis ch 2.4]

[Held and Bove - Likelihood and Bayesian Inference ch 3]

[Hobbs and Hooten - 4.2 Likelihood profiles] 



### Sources and Other Resources

  This module is a synthesis of ideas and code found in...  
<div style="margin-left: 1em;"> 
  [Dan Gibson's Nest Survival Code](https://dan-gibson.weebly.com/nest-survival-jags.html)  
  Hobbs and Hooten - Bayesian Models: A Statistical primer for Ecologists  
  McElreath - Statistical Rethinking: A Bayesian Course with Examples in R and Stan  
  Kery - Introduction to WinBUGS for Ecologists: A Bayesian approach to regression, ANOVA, mixed models and related analyses  
  Kery and Schaub - Bayesian Population Analysis using WinBUGS: A Hierarchical Perspective
</div>
  
I have also found the below resources useful in familiarizing myself with and better understanding bayesian concepts and applications.  
  <div style="margin-left: 1em;">  
  [Olivier Giminez's Youtube Channel](https://www.youtube.com/c/OlivierGimenez)  
  [Richard McElreath's Youtube Channel](https://www.youtube.com/channel/UCNJK6_DZvcMqNSzQdEkzvzA/about)  
  [ritvikmath Youtube Channel](https://www.youtube.com/c/ritvikmath)  
  [Fox 2011 - Frequentist vs. Bayesian statistics: resources to help you choose](https://dynamicecology.wordpress.com/2011/10/11/frequentist-vs-bayesian-statistics-resources-to-help-you-choose/)  
  [McGill 2013 - Why saying you are a bayesian is a low information statement](https://dynamicecology.wordpress.com/2013/06/19/why-saying-you-are-a-bayesian-is-a-low-information-statement/)  
  [rasmusab Youtube Channel](https://www.youtube.com/channel/UCO7kJ__JJ4v4RQU3ZymR3Kw)
    
      
  </div>