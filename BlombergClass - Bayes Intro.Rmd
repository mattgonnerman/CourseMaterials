---
title: "A Practical Introduction to Bayesian Modeling"
subtitle: "Wild Turkey Survival in JAGS"
author: "Matthew Gonnerman"
output: html_document
---

```{r, setup, include=FALSE}
lapply(c("dplyr",
         # "ggplot2", 
         "R2jags",
         "RMark", 
         "gtools"),
       require,
       character.only = T,
       quietly = T) #Whether to report successful loading of packages 
```
### Outline:
[This Lesson...]  
[Bayes Theorem]  
[Describing Our Model System]  
[Building Our Survival Model]  
[Prepare the R Environment]  
[Simulating our Model System]   
[From Hypothesis to Model]  
[Alternative MCMC Samplers]  
[A Frequentist Alternative: RMark]  
[Comparing Bayesian and Frequentist Approaches]  
[Sources and Other Resources]  


### This Lesson...
This exercise is meant as an introductory point for you to learn about the theory behind and application of Bayesian statistics. With that in mind, this will be a surface level exploration of foundational concepts and how to apply these concepts to answer specific research questions. I hope to achieve the following objectives...

<div style="margin-left: 1em;"> 1) To demonstrate how to formulate and code a Bayesian analysis in R from conception through model diagnostics.   
2) To outline common decisions that must be made throughout process and provide relevant background to inform that decision making process. 
3) Compare methods and results from a Bayesian and Frequentist approach to help show when each framework is most appropriate to use.  
 </div>



### Bayes Theorem
Before we begin any actual analysis, let's briefly introduce the foundational equation behind Bayesian statistics, called **Bayes Theorem**. Assume there is a study system which is experiencing some relationship which we wish to approximate. Let the unknown effects defining the relationship and any associated uncertainty be represented by $\theta$ and any information we collect to describe the effect be represented as *y*. We wish to ask what are the most likely values for $\theta$ given *y*, otherwise written as $Pr(\theta|y)$. We can approach this question by considering the joint probability of *y* and $\theta$ occurring together, otherwise written as $P(y, \theta)$. This probability can be rewritten using basic rules of conditional probability as shown below...   

$$ Pr(y, \theta) = Pr(\theta|y)Pr(y) = Pr(y|\theta) Pr(\theta)$$  

When we breakdown these probability statements, we find that the probability of both *y* and $\theta$ occurring together is the same as the probability of *y* occurring multiplied by the probability of $\theta$ occurring given that y also occurs (this can also be written with y and $\theta$ reversed). Using basic algebra, we can rearrange our equation to create the below statement, which is Bayes Theorem, and it provides a means to estimate the most appropriate value for $\theta$ given observed values for *y*.  
$$ Pr(\theta|y) = \frac{Pr(y|\theta) Pr(\theta)}{Pr(y)}$$
#### Linking Theory and Information
Let's briefly breakdown each component within this equation to better understand what each means and what purpose they serve. For more in depth descriptions of Bayes theorem and its components, check out chapter 2 in Statistical Rethinking or chapter 5 in Hobbs and Hooten 2015.

**Posterior Distribution** - $Pr(\theta|y)$  
We will start on the left hand side of the equation with the posterior distribution, which is "the relative plausibility of different values for $\theta$, conditional on the data" (from Statistical Rethinking). This means that we can use the posterior distribution to describe our estimates of unknown parameters based on the data and priors provided to the model. 

A key characteristic of the posterior distribution is that it integrates to 1. This has mathematical implications, but what it means practically is that we are able to me probabilistic statements about $\theta$, which is not possible using other likelihood approaches such as MLE. This also means that unknown values such as $\theta$ can be treated as random variables, which differentiates Bayesian from Frequentist approaches. 

**Likelihood** - $Pr(y|\theta)$  
For those familiar with Maximum Likelihood Estimation, the likelihood of Bayes Theorem functions very similarly, linking unobserved parameters with known information to find the most likely values of $\theta$ given observed values for *y*.   

**Prior Distribution** - $Pr(\theta)$  
The prior distribution represents any information we have about $\theta$ prior to collecting data. This can be in the form of an **informative** or **uninformative** prior distribution. An informative prior implies that we have some prior knowledge about the system we are working with. This could be previous research that has estimated the same or similar parameters as those you are interested and therefore can be used to constrain our estimates. It may also be more vague, such as in the form of expert opinion, which is used to more weakly influence our estimates but still accommodates our expectations about the system. Prior information can be as vague as knowing which type of distribution should be used as a prior for a given parameter. 

In the same way that a prior can represent our knowledge of a parameter, it can also be used to represent that we don't have any prior knowledge of a system and adjust our estimates accordingly. In such cases, we often choose to use some flat prior distribution, otherwise called "uninformative". This nomenclature is a bit confusing because any prior we use implies some information. This could be a uniform distribution across a set of values, a normal distribution with a mean of 0 and a very large standard deviation, or a beta distribution. Each decision relies on some knowledge of the system and what values are reasonable/expected. While integrating our lack of information may seem arbitrary, in practice the use of such priors can have regularizing effects on posterior estimates. This means that even the most basic of priors will have some pull towards the center, which can greatly improve posterior estimates. These regularizing effects are especially useful when working with very limited data.
  
*Aside:* Prior information is often incorrectly attributed as a defining feature of Bayesian statistics. While not often integrated into alternative approaches, use of prior information is not unique to Bayesian statistics but it is required to conduct Bayesian statistics.  

**Joint Distribution** - $Pr(y|\theta)Pr(\theta)$  
The joint distribution is the product of the likelihood and the prior distribution and is proportional to the posterior distribution. This means where the joint distribution is maximized, the posterior distribution will also be maximized.

**Marginal Distribution** - $Pr(y)$  
The marginal distribution defines the probability that the observed data would occur, which is a rather abstract idea. Mathematically, the marginal distribution is equivalent to the integral of the joint distribution and is used to ensure that the posterior distribution integrate to 1. Put simply, dividing by the marginal distribution means that the posterior distribution will be a probabilistic statement. 

Later we will discuss how Bayes theorem is applied to Markov Chain Monte Carlo simulations to sample from the joint distribution and estimate the posterior distribution, but first lets take a break from statistics and introduce a model system that we can use as our example.

### Describing Our Model System
#### Research Question and Hypotheses
For this module, we will be estimating survival rates using repeated observations of an individual. As this lesson is geared towards the Bayesian implementation of already conceived modeling techniques, I won't be going into much detail on the reasoning and derivation of daily survival rate models. For those unfamiliar, I would suggest <a href="https://doi.org/10.1890/0012-9658(2002)083[3476:ATFMAN]2.0.CO;2">Dinsmore et al. 2002</a> or, for a more detailed discussion on the data requirements and formatting, read [the MARK program documentation](http://www.phidot.org/software/mark/docs/book/pdf/chap17.pdf).

Since we all have different backgrounds and study animals, let's posit a hypothetical ecological question that is broadly relevant for management. I spent graduate school studying wild turkey ecology, so let's use survival rates within turkey populations in New England as our study system. While turkeys can subsist on hardwood mast throughout the winter in core areas of the species range, deep snow depths and icy conditions inhibit a turkey's ability to find adequate food sources at their northern range limit. At the same time, low temperatures and high winds make thermoregulation more difficult which increases energetic demands. So knowing that winter is a period of increased stress and mortality for turkeys, we may wish to ask the question **what factors influence daily survival of wild turkeys in winter?** 

To address this question, we will need to propose hypotheses to evaluate. For example, we may expect birds that are generally healthy to be better equipped to deal with harsh conditions and inadequate food. Alternatively, maybe the type of habitat a turkey occupies will influence the availability of natural and anthropogenic food sources. With these two ideas in mind, our hypotheses will be...

<div style="margin-left: 1em;"> 
1) Decreased survival rates will be associated with decreased body condition metrics at capture.
2) Turkeys that primarily occupy suburban landscapes will experience increased survival compared to those that occupy agricultural or forested landscapes.
</div>

#### Data and Unknowns
Clearly stated hypotheses are an important step in producing transparent and unbiased research, but they are also generally useful for providing guidance during model building. By explicitly formulating research questions and potential hypotheses, we are able to identify components that will comprise our model;known and unknown information. Consider that we "view data as the observed realizations of stochastic systems that contain one or several random processes" (Kery 2010). To simplify this statement, our known information is determined by a series of processes that are defined by the unknown information that we wish to estimate. In general, known information is comprised of the data collected to describe some effect or relationships. So in the case of wild turkey winter survival, we could use radio-telemetry to monitor turkeys through the winter. The data we collect will be our known information comprised of the live/dead status of each bird at each visit. It will also include any ancillary information we want to relate to survival, which in our case is individual turkey biometrics (body condition at capture) and landscape information (major land cover class). 

Determining what constitutes relevant unknown information is a more complicated task as it requires familiarity with the statistical methods. This is because, depending on what we think is affecting survival and how we choose to measure it, there are many parameters and sources of variation that we could potentially include into our model. For example, if we were to conduct a mark-recapture study to determine survival, is there some observation process (i.e., variable detection rates) that must be incorporated to account for imperfect detections? Similarly, if we are going to use covariates such as body metrics and habitat to describe variation in survival, we will need to estimate parameters to describe those beta coefficients and the regression intercept. We can also try to account for many of the sources of noise in our system, such as incorporating random effects to describe unmeasured variation among individuals or groups of individuals. As you can tell, the number of parameters we need to estimate increases quickly as we add assumptions and additional data sources. Importantly, though we won't explicitly measure and incorporate every potential variable that influences survival, we can still account for them indirectly in the model through these different error sources, such as random effects. This list could be endless as you can make the model as complicated or simple as you desire, so an important step is differentiating what is relevant to your research question. This will likely be dependent on the question you are asking, your prior knowledge of the system, and the potential monitoring and management options. So to determine what all the unknowns of our proposed system are, let's jump into model construction.

### Building Our Survival Model
We are next going to attempt to construct a daily survival rate model from scratch. There is no correct way to go about model construction, so I will offer up my approach as one option. First, let's identify all known information that we will be inputting into the model. For the purposes of learning, we will ignore the intricacies of coding a model and focus more on first constructing a theoretical model and then code it later. 

First, we have our observed survival information in the form of daily live/dead statuses for each individual visited, which we will abbreviate as *Obs*. We also have the body condition of each bird, *BC*, and whether a turkey was in a suburban, forested (*FOR*), or agriculture (*AG*) dominated landscape. We next need to describe our observed data *Obs* according to the underlying process that determines individual survival outcomes. When we simplify this relationship, it becomes a weighted coin-toss with a binary outcome. Every day a turkey will either survive to the next day or die. For such "coin-toss" dynamics, it is common to use a Bernoulli distribution, which has a single parameter which we will abbreviae to *S*. We can right the relationship between *Obs* and *S* as

$$Obs \sim \text{Bernoulli}(S)$$
which says that the probability of observing a bird alive on a given day follows a bernoulli distribution with a probability of *S*. If we believe that *S* will differ among individuals, we can add notation *i* as a subscript to denote differences in survival among individuals...

$$Obs_i \sim \text{Bernoulli}(S_i)$$

Considering that our hypotheses specify such individual differences in survival associated with body condition and habitat, we will need a means to estimate variation in *S* by these covariates. This can be achieved using linear regression

$$
S_i = \alpha + \boldsymbol{\beta X_i} + \epsilon 
$$

where $\alpha$ is an intercept term, $\boldsymbol{\beta X_i}$ is a series of beta coefficients and associated individual-specific covariate values, and $\epsilon$ represents unspecified variation in *S*. However, because *S* is a probability, it must be constrained between 0 and 1 which is not the case for the above equation. Instead, we can use the logit link function to ensure that *S* remains within realistic boundaries...

$$ 
S_i = \frac{exp(\alpha + \boldsymbol{\beta X_i} + \epsilon)}{1 + exp(\alpha + \boldsymbol{\beta X_i} + \epsilon)}
$$

or written more simply...

$$
\text{logit}(S_i) = \alpha + \boldsymbol{\beta X_i} + \epsilon
$$

So based on the model thus far, our unknown parameters include *S*, $\alpha, \beta, \textrm{ and }\epsilon$. We can estimate all of these with our proposed data, but we will also need to supply some prior values. Considering this is a hypothetical relationship, we will keep things simple and use uninformative priors. Uninformative priors for beta coefficients and error terms such as $\beta \textrm{ and }\epsilon$ can take many forms, but a simple option is a 0 centered normal distribution with a very wide standard deviation 

$$
\beta \sim \text{Normal}(\mu = 0,\sigma = 10000)
$$
Aside: This is a good place to bring up some terms which you will see frequently that are worth differentiating here, parameters versus hyperparameters. A **parameter** defines the system process which we are attempting to estimate and a **hyperparameter** is a parameters of the prior distribution which define other parameters. Think of it as levels, if a parameter defines another parameter via some distribution, then it is a hyperparameter. And a hyperparameter itself can be drawn from a prior with its own hyperparameters. So in our example, $\beta$ would be considered a parameter and $\mu$ and $\sigma$ are hyperparameters.

We will also wish to provide a starting value for $\alpha$, but this will be slightly more complicated. Remember that for a linear regression, $\alpha$ represents the expected value when all covariates are equal to 0. Therefore, $\alpha$ is the probabiltiy of survival when all covariates (*BC*, *FOR*, and *AG*) equal 0 and must be constrained to between 0 and 1. We can do this using a flat beta distribution and the logit link function


$$
\text{logit(}\alpha) = \text{Beta}(1,1)
$$

When we combine all of these statements together, we have a basic Bayesian model for survival

$$
Obs_i \sim \text{Bernoulli}(S_i)\\
\text{logit}(S_i) = \alpha + \boldsymbol{\beta X_i} + \epsilon \\
\text{logit(}\alpha) \sim \text{Beta}(1,1) \\
\beta \sim \text{Normal}(\mu = 0,\sigma = 10000) \\
\epsilon \sim \text{Normal}(\mu = 0,\sigma = 10000)
$$


### From Model to Code
So now that we have a conceptual model, we need to translate the hypothesized relationship into code that a computer can interpret. Currently, you are most likely to encounter some version of the BUGS language, which is used in a variety of MCMC software including what we will use, JAGS. This language is especially useful for ecologists who may not be familiar with higher level maths, as it allows for the distillation of complex likelihood statements into simple probability distributions. For example, in our model specify a prior for our regression intercept using a beta distribution, but under the hood JAGS is actually dealing with [more intricate equations](https://en.wikipedia.org/wiki/Beta_distribution#Probability_density_function) when sampling from the posterior. There will be many intricacies involved with translating and coding your models, but our proposed survival model provides some excellent beginner modeling examples for the most common components of a BUGS model. 

#### Nodes
In any model you make, estimated parameters are considered **nodes** within the model, which will often be referenced in any error messages you receive. For every model, nodes must be defined in one of three ways. **Stochastic** nodes are random parameters that are specified by a distribution within the model. Using our above model as an example, *Obs*, $\alpha$, $\beta$, and $\epsilon$ are all stochasitic as they rely on some prior distribution to define them. **Deterministic** nodes are logical functions of other nodes within the model, such as intermediary parameters such as *S*. Finally, **constants** are nodes which have been specified in a separate data file and provided to the model. These are often used as indexing variables which allow for outcomes to be linked with individual/time/location specific covariates (e.g., subscript *i* in the example model will become a constant). Regardless of which type, all nodes must defined by either a prior distribution, other parameters within the model, or by data supplied to the model. Failure to meet this criteria will result in an error message. 

#### Prior Distributions
[Selecting a Prior Distribution] [Conjugate Priors - Hobbs and Hooten CH 5.3] 

Aside: [One of the most common distributions you will use, dnorm, is commonly specified by a mean and standard deviation  using precision instead of sd, common so important to note]

#### Indexing and Dynamic Indexing
There will be occasions where you need to link parameters according to associated factors, such as coefficients within a regression model or when tracking outcomes according to unique individuals. In such cases, you can use indexing just like regular r code. For those unfamiliar, indexing is used in functions such as for loops to iteratively run calculation on a set of values. To apply this to our example, we hypothesized that each individual will experience unique survival rates according to habitat and body condition. To translate this into code for JAGS, we can use the below code to create a for-loop to estimate an individual specific daily survival rate.   

```{r, eval = F}
  for(i in 1:n.ind){
      logit(DSR[i]) <- a.S + b.bc*x.bc[i] + b.ag*x.ag[i] + b.for*x.for[i]
    }
```
Now we have a new problem, we need to make sure each unique observation (i.e., each live/dead status) is linked to the correct survival rate for each turkey. This can be solved with a *dynamic index*, which is vector of constants which themselves are indexes referencing the correct node. 

```{r}
for(j in 1:n.obs){
  obs.S[j] ~ dbern(DSR[turkey.id[j]])
}
```
Here, "turkey.id" is a vector with length equal to the number of observations and each value within the vector references a specific turkey (otherwise *i* in the previous for loop). We use index *j* to call a specific turkey ID within the dynamic index, which then calls a specific daily survival rate to use as a probability within the bernoulli trial.

#### Non-Uniform Data
[JAGS does not like missing values] [Unforunately I have never seen a perfect data set, which means we have to code our model to account for any gaps in visits or missing data.] [This can be done any number of ways, but the big takeaway is that NAs in your datasets will always cause issues so need to premept potential issues or be able to adjust code to handle it]. [For our example, it is probably unrealistic to assume you will find all birds on all days.] [Maybe a technician was sick for a day or a specific turkey moved an unexpectedly large distance and could not be found.] [Thus we need to structure our data to account for these missing days.]   

```{r, eval = F}
for(j in 1:n.obs){
    period.S[j] <- pow(DSR[turkey.id[j]], interval[j]) # Total probability of survival since previous visit
    obs.S[j] ~ dbern(period.S[j]) # Observation process follows bernoulli distribution
  }
```

If we combine everything we have above to translate our theroretical model into a BUGS model, you get the below result. Notice that it is wrapped inside of a function, which is purely a functional aspect of the R2JAGS package we are using. 
```{r}
JAGS.turkey.S.model <- function(){
  ###Priors
  base.S ~ dbeta(1,1) 
  a.S <- logit(base.S) 
  b.bc ~ dnorm(0, 1/100) 
  b.ag ~ dnorm(0, 1/100)
  b.for ~ dnorm(0, 1/100)
  
  
  ###LIKELIHOOD
  for(i in 1:n.ind){
      logit(DSR[i]) <- a.S + b.bc*x.bc[i] + b.ag*x.ag[i] + b.for*x.for[i]
    }
  
  for(j in 1:n.obs){
    period.S[j] <- pow(DSR[turkey.id[j]], interval[j]) # Total probability of survival since previous visit
    obs.S[j] ~ dbern(period.S[j]) # Observation process follows bernoulli distribution
  }
}
```


#### Prepare the R Environment
Now that we have a model, we can test how well it approximates survival by simulating some data and running it in R. To do this, let's first ensure the R environment has the necessary tools. We will first install, update, and load the packages we will use throughout our code. Just as a reminder, **if you are already working on other R coding projects, updating packages can have cascading effects on code functionality.** If these packages are already installed and have relatively recently been updated, then you are fine to skip this step.  I only add this reminder as many people will go to install/update packages, causing their functioning code to suddenly stop working, leading to an understandable freak out. Luckily, your code is most likely not broken, you will just have to determine which functions were updated and adjust your code to match the new functionality. 

```{r, eval = F}
install.packages("dplyr", "gtools", "R2jags", "RMark")
lapply(c("dplyr", #Data management
         "gtools", #Easy link functions
         "R2jags", "RMark"), #Running models
       require, #Function called to load packages
       character.only = T) #Necessary for lapply functionality
```

In addition to making sure packages are loaded, we will also want to ensure that the programs we are using are correctly installed and communicating with R. We will be using 2 programs for this lesson; [JAGS](https://mcmc-jags.sourceforge.io/) and [MARK](http://www.phidot.org/software/mark/). These programs interact with R2Jags and RMark respectively to run the models we will supply. If not already installed on your computer, you can follow the links provided, navigate to the installation pages and follow the instructions to get these programs installed. Often times, if there are issues with this step, it is because the program was installed in an non-standard location (e.g., "C:\\Program Files").

This is also a good place to share some unsolicited advice which I received too late in my graduate career. Before you actually start coding, stop to think through the organization and workflow of your project, from data collection through assessing model results. Then, identify the major steps to implementing your code and consider breaking up your R script into sections that reflect these steps. Even with extensive comments, having 100's of lines of code within a single script can make reading code and diagnosing issues very difficult. By breaking up and sourcing our scripts like this, we can better create manageable chunks of code that are well organized and easily referenced. For example, here is how I usually break up and source my code, although I often times have even more divisions within each section depending on what I am doing.   
```{r eval = F}
source("1 - DataManagementCode.R")
source("2 - JAGSModelCode.R")
source("3 - RunJAGSCode.R")
source("4 - SummarizeOutput.R")
source("5 - CreateFigures.R")
```

### Simulating our Model System
#### Simulate individual turkey characteristics and associated weather information
Now that we have laid out our research question and hypotheses, let's simulate some data. Simulated data will be  useful for learning these concepts but it also provides a level of control that facilitates model construction. Specifically, by generating data on which our model can be constructed, we will know whether our model outputs are accurate to the real values, which we can specify to be any value we wish. It also allows us to introduce noise into data collection, which will allow us to assess how the model reacts to random variation in the observation process. If we were to start with real data, we would have much less capacity to determine whether the values we were getting were accurate.

We are going to start by setting values for the parameters that we will ultimately estimate and compare our model results to. 
```{r}
##Simulated turkey survival
mean.DSR <- 0.99  #base daily survival rate
alpha.s <- logit(mean.DSR) #Use logit link to create an intercept

# Effects on daily survival
beta.body <- .003 #Body Condition
beta.ag <- .5 #Agriculture
beta.for <- -1 #Forested
```
Using the above code, our baseline daily survival rate is set to .99, which means that averaged across all birds, the probability of surviving a given day is 99%. While this may seem high, consider that you will exponentiate this value across multiple days, which adds up fast. Across 10 days, a 99% daily survival rate translate to only a ~90% chance of survival. We will also set the effect sizes for body condition and habitat.You will notice that there are two values for habitat and only one for body condition. That is because we will be treating habitat as a categorical variable (more on that below). 

Now that we have defined how the system will influence turkeys, we need to generate some data to supply to our model. This will be a multiple step process, where we first generate individual turkeys with unique characteristics for body condition and habitat. We will then simulate the real survival history of each bird based on their individual characteristics and the preset system influences we just defined. Finally, we will simulate our observation of that birds survival history. So lets start generating some hypothetical turkeys...

```{r}
#Simulate individual turkey characteristics
n.turkey <- 250  #number of simulated turkeys

turkey.sim <- matrix(NA, nrow = n.turkey, ncol = 5)
for(i in 1:n.turkey){
  #Body Condition Metric, referenced to mean body condition (pre-z-standardized)
  turkey.sim[i,1] <- rnorm(1, mean = 0, sd = 1) 
  
  #Categorical covariate for Landscape, need dummy code it
  h <- sample(1:3, 1) #1 = Suburban, 2 = Agriculture, 3 = Forested
  turkey.sim[i,2] <-  ifelse(h == 2, 1, 0)
  turkey.sim[i,3] <-  ifelse(h == 3, 1, 0)
  
  #Random variation associated with individual turkeys
  turkey.sim[i,4] <- rnorm(1, mean = 0, sd = .1) 
  
  #We can now combine individual betas to define individual survival rates
  turkey.sim[i,5] <- gtools::inv.logit(alpha.s + beta.body*turkey.sim[i,1] + beta.ag*turkey.sim[i,2] +
                                             beta.for*turkey.sim[i,3] + turkey.sim[i,4])
    
}
```
This code starts by defining the total sample size we will be working with, 250 individual turkeys. We then created a matrix where each row corresponds to each turkey and each column in a covariate value. The first column in the matrix defines body condition for each bird, which I assumed to be z-standardized. This makes simulation much easier as I can just use a 0 centered normal distribution, but this can also be useful for comparing effect sizes across multiple covariates which are measured using different units or have different magnitudes. Columns 2 and 3 define whether a bird primarily exists in a suburban, agricultural, or forested landscape. As this is a categorical covariate, we will use "dummy coding" to specify which beta coefficient should apply to each bird. 

You will also notice a fourth column which represents unmeasured variation in survival among individuals. Consider this to be a summary of all of the other aspects of an individuals characteristics and environment which we either don't care about or could not measure. You can adjust these values to be as big or as little as you like, depending on how much additional variation you would normally expect in your data. 

We can then calculate a mean survival rate for each bird using a linear regression as shown in the fifth column.This is the value that will be used in the next step to simulate the "real" survival for each turkey. 

####Simulate Real Survival History
```{r}
w.days <- 90  #number of days turkeys are monitored for

#We can use a bernoulli trial (weighted coin flip) to simulate survival, assuming a bird was alive, need to make sure that they all start alive at capture, all birds assumed caught Dec 31. 
ind.surv.hist <- matrix(NA, nrow = n.turkey, ncol = w.days+1)
ind.surv.hist[,1] <- 1 #First day is day of capture, set to 1 since known alive

#Combine if/else statement with forloop to simulate
for(i in 1:n.turkey){
  for(t in 2:(w.days+1)){
    if(ind.surv.hist[i, t-1] == 1){ #If the bird was alive at previous visit
      ind.surv.hist[i, t] <- rbinom(1,1, turkey.sim[i,5]) 
    }else{
      break #ends the loop for this bird if it has died
    }
  }
}

#Before we move on, lets change the NAs in the matrix to 0, as once a bird dies it is dead for good.
ind.surv.hist[is.na(ind.surv.hist)] <- 0
```
We can then look at the data to ensure nothing appears incorrrectly. For example, we can check individual histories to ensure nothing looks out of place. 
```{r}
#Encounter history for first bird
ind.surv.hist[1,]
```

Or we may wish to know how many individuals survived in total, which should give us a rough idea of whether our simulation is correctly specified or if our initial values are too unrealistic.
```{r}
#Lets see how many survived
sum(ind.surv.hist[,w.days + 1])
```

####Simulate Observed Survival History
[Real --> Observed]

```{r}
obs.rate <- .95 #We can't expect to observe each turkey every day, so this just randomizes whether we successfully collect data on a bird on a given day. Let's assume that on average we find a bird every 4 days.

obs.hist.mat <- matrix(NA, nrow = n.turkey, ncol = w.days + 1)
obs.hist.mat[,1] <- 1 #We know the bird was alive at capture
#Now we can simulate our technicians going out and doing the work to collect our data.
for(i in 1:n.turkey){
  for(t in 2:(w.days+1)){
    succ.obs <- rbinom(1,1, obs.rate)
    
    if(succ.obs == 1){
      obs.hist.mat[i, t] <- ind.surv.hist[i, t]
      
      if(ind.surv.hist[i, t] == 0){ #if the bird is dead we would stop checking on it
        break #so we exit loop for this bird when we identify a mortality
      }
    }
  }
}
```
### MCMC: Sampling from the Posterior
[Bayesian Inference is just counting]

[Simulated draws from the posterior]

#### Markvoc Chain Monte Carlo Simulations

[Potential Sampling Approaches]

### Running the Model in JAGS
#### MCMC Decisions
There are quite a few options that need to be made when you run a MCMC. These will largely influence model convergence/run time.  [Broadly describe some decions.] The big issue many people run into when making these decisions which can slow them down is they are trying to find some correct answer, when in many cases these decisions are subject to the circumstances of the model, data, and researcher. So lets walk through some of these major questions.  

**Starting Values** - [Where you tell the MCMC to begin sampling for a given parameter value can affect run time] [For a correctly specified model, this shouldn't affect results]  

[In certain instances, if you let the model choose its own starting values, it can results in impossible relationships, which will cause errors when you try to run the model. For example, if you accidentally supply a negative value to a distribution constrained above 0. By specifying a starting value, you allow the model to start in a realistic location]

[Also important to note, these programs hate NA values. So this may be another place where you need to supply starting information so there are no NA values]

**Burn-in Time** -  

**Sampling Method** -  

**Coding Language** - There are many ways that you can code and run an MCMC. We will focus on two coding frameworks that are currently most widely used among ecologists **JAGS** and **NIMBLE**. [BUGS language]. [Similarities]. [Differences]. [When to choose one of the other].  

[Parallel Processing]


#### Data Packaging
Reformatting data to get what we want.

```{r}
### Format data to make compatible with model specification
# Remove first column (capture day) from encounter history, will not be used
obs.hist.mat.noDay1 <- obs.hist.mat[,-1]

# JAGS doesn't like NAs, so we need to simplify observation history. 
# An easy way to do this is to convert it to a vector
obs.hist.vec <- as.vector(t(obs.hist.mat.noDay1))
obs.hist <- obs.hist.vec[!is.na(obs.hist.vec)]

# Vector format requires a bit more information to function correctly
# For example, we need a vector to tell the model which bird we are referencing for each visit
ID <- matrix(1:n.turkey, nrow = n.turkey, ncol = w.days)
ID <- as.vector(t(ID))
ID <- ID[!is.na(obs.hist.vec)]      # ID marker

# We also need to know how long since the last visit
visit_ind <- matrix(NA, ncol = ncol(obs.hist.mat), nrow = nrow(obs.hist.mat))
get.last <- function(x) max(which(!is.na(x)))

for(i in 1:n.turkey){
  for(j in 2:(w.days+1)){
    if(is.na(obs.hist.mat[i,j]) == FALSE){
      visit_ind[i,j] <- j - get.last(obs.hist.mat[i,1:(j-1)])
    }
  }
}

interval <- as.vector(t(visit_ind))
interval <- interval[!is.na(interval)]
```



Packaging everything up. As you can see in our model, we are going to need to reformatting of our data to get it into format our model can udnerstand and use. For example, I made a huge mistake when I initially thought up this model and thought of a time varying covariate (weather). These are much harder to code compared to characteristics of an individual or system that dont change between observations. This is specifically difficult because 
```{r}
#Data to supply to the model
data.list <- list(
  #Observation Information
  obs.S = obs.hist, #Vector containing observed survival history
  turkey.id = ID, #Vector describing which turkey an observation was for
  interval = interval,#Time since last visit
  
  n.ind = nrow(turkey.sim), #Number of individual turkeys monitored
  n.obs = length(obs.hist), #Number of total observations
  
  #Covariate Information
  x.bc = turkey.sim[,1], #Vector describing body condition for a given turkey
  x.ag = turkey.sim[,2], #Vector describing whether a turkey primarily uses agriculture landscape
  x.for = turkey.sim[,3] #Vector describing whether a turkey primarily uses forested landscape
)

#Parameter Monitors
parameters.list <-c(
  #Regression Coefficients
  "a.S",
  "b.bc",
  "b.ag",
  "b.for"
)

#Initial Values
inits.list <- function(){
  list(
    base.S = .998 #Set initial value for base survival rate
  )
}
```

#### Considerations for Run Time
One of the biggest goals of MCMC analysis is to have the model converge as quickly as possible. [Convergence time will be determined by a number of factors.] There will be many factors affecting run time and many decisions you can make to reduce it. 

**Number of parameters to estimate** - [More nodes means more combinations means more simulations?]  
  
**Data Size** - [Amount of data you have will ]  
  
**Iterations** - [Longer simulations = bigger sample size esentially] 
  
**Burn In Period** - [Model needs time to find a stable equilibrium]    

**Thinning** - [Initially used to help with autocorrelation, but arguments against thinning...wasted data]  

**Number of Chains** -   
  
**Parallel Processing** -  Depending 

**Initial Values** - [Starting Closer to posterior maximum can aid in convergence]

[These decisions will be consistent across coding options, although implimentation may differ.]


#### Running the Model  
```{r}
#Make final MCMC related decisions
ni <- 2000 #Iterations
nb <- 1000 #Burn-In
nt <- 1 #Thinning
nc <- 3 #Chains

#Run the model
Surv_JAGS_output <- R2jags::jags(data = data.list,
                         parameters.to.save = parameters.list,
                         inits = inits.list,
                         model.file = JAGS.turkey.S.model,
                         n.iter = ni,
                         n.burnin = nb,
                         n.thin = nt,
                         n.chains = nc) 
```
#### Common Errors
[Heather Gaya GitHub](https://github.com/heathergaya/JAGS-NIMBLE-Tutorials/tree/master/JAGS_Errors)

#### Model Diagnostics and Reporting Results (JAGS)
[Different components of the output object]

[Trace Plots]
```{r}
traceplot(Surv_JAGS_output, #bugs output object
          mfrow = c(3,2), #Rows and Columns in figure
          ask = F, #Ask before plotting?
          varname = c("b.ag", "b.for", "b.bc")) #Which parameters to plot
```

```{r}
#Basic Parameter Estimates
print(Surv_JAGS_output)
```

If we want to run a more in-depth diagnostics of our model, it can be useful to extract the actual MCMC chains. This allows for the running of various diagnostic functions.
```{r}
#Convert BUGS output into MCMC for further information and plotting options
Surv_JAGS_MCMC <- as.mcmc(Surv_JAGS_output)
summary(Surv_JAGS_MCMC)

```

```{r, eval = F}
require(coda)
gelman.plot(Surv_JAGS_MCMC)

heidel.diag(Surv_JAGS_MCMC)
```

#### Failure to Converge
[Before rewriting your model, it may be worth first adjusting MCMC options] [Interations/BurnIn time] [Starting Values]

https://cran.r-project.org/web/packages/EcoDiet/vignettes/convergence_problems.html

[Using the original MCMC run to continue simulations with the same model]
```{r, eval = F}
Surv_JAGS_update <- update(Surv_JAGS_output, n.iter = 1000) #Continues the same simulation, adding iterations 
Surv_JAGS_update <- autojags(Surv_JAGS_output) #Automatically updates model until convergence
```

#### Evaluating and Presenting Results
[Posterior Distribution]

Aside: This seems like a relevant time to bring up an important note about interpretting results from logistic regression, specifically differentiating between **absolute** and **relative** effects. Relative effects refer to the logit link estimate of a beta coefficient and gives the **proportional change in odds** of an outcome.  Absolute effects refer to differences in the final probabilities being estimated and will depend on the entire regression formula. I will point readers to chapter 10 of *Statistical Rethinking* for a more in depth discussion and examples of these two. I bring it up now because we are dealing with effects acting on a event that already has ~99% chance of occurring (surviving a single day). When applying logisitic regression to events that happen with great regularity or extremely rarely, it is often best to evaluate both the relative and absolute differences in the outcome. This is because near these limits (0,1) there is less room for loss/growth and therefore a greater range of values can explain the observed differences in the rate of an outcome. 

### Alternative MCMC Samplers
[What is different about NIMBLE] [Coding similarities/differences]







### A Frequentist Alternative: RMark 
[Very quickly show how easily this could be coded using RMark].  
  
So you may be thinking, "if its so easy to do this using a frequentist framework, why in the world did you make me do this long exercise?!."  

#### Direct Comparisons
**Integrating Models** - XXX  

**Intuitive Description of Uncertainty** - [Hypothetical Replicates vs Probability Statements]  

**Pior information** - XXX  

**Ease of Use** - XXX  

**Computational Limitations** - XXX  


[So now that you know how to do this under a bayesian framework, and you've seen how complicated it is, how would we run the same analysis as a frequentist?]


[Phidot link](http://www.phidot.org/software/mark/docs/book/pdf/chap17.pdf)



### Comparing Bayesian and Frequentist Approaches
**Definition of Unknown Parameters** - XXX  

**Randomness vs Uncertainty** - [Randomness (frequentist) vs uncertainty (Bayesian) - Nothing is actually random, if we had enough information and a powerful enough computer, you could predict almost any natural system in theory]  

**Pior information** - XXX  

**Ease of Use** - XXX  

**Computational Limitations** - XXX  


[Kery and Schaub - Bayesian pop analysis ch 2.4]

[Held and Bove - Likelihood and Bayesian Inference ch 3]

[Hobbs and Hooten - 4.2 Likelihood profiles] 



### Sources and Other Resources

  This module is a synthesis of ideas and code found in...  
<div style="margin-left: 1em;"> 
  [Dan Gibson's Nest Survival Code](https://dan-gibson.weebly.com/nest-survival-jags.html)  
  Hobbs and Hooten - Bayesian Models: A Statistical primer for Ecologists  
  McElreath - Statistical Rethinking: A Bayesian Course with Examples in R and Stan  
  Kery - Introduction to WinBUGS for Ecologists: A Bayesian approach to regression, ANOVA, mixed models and related analyses  
  Kery and Schaub - Bayesian Population Analysis using WinBUGS: A Hierarchical Perspective
</div>
  
I have also found the below resources useful in familiarizing myself with and better understanding bayesian concepts and applications.  
  <div style="margin-left: 1em;">  
  [Olivier Giminez's Youtube Channel](https://www.youtube.com/c/OlivierGimenez)  
  [Richard McElreath's Youtube Channel](https://www.youtube.com/channel/UCNJK6_DZvcMqNSzQdEkzvzA/about)  
  [ritvikmath Youtube Channel](https://www.youtube.com/c/ritvikmath)  
  [Fox 2011 - Frequentist vs. Bayesian statistics: resources to help you choose](https://dynamicecology.wordpress.com/2011/10/11/frequentist-vs-bayesian-statistics-resources-to-help-you-choose/)  
  [McGill 2013 - Why saying you are a bayesian is a low information statement](https://dynamicecology.wordpress.com/2013/06/19/why-saying-you-are-a-bayesian-is-a-low-information-statement/)  
  [rasmusab Youtube Channel](https://www.youtube.com/channel/UCO7kJ__JJ4v4RQU3ZymR3Kw)
    
      
  </div>